# Basic_Transformer

This repo contains the most basic Transformer architecture, mostly following the "Attention Is All You Need" paper. For conceptual overview, I found the following article series helpful: 

https://medium.com/@hunter-j-phillips/overview-the-implemented-transformer-eafd87fe9589

Another Transformer implementation: 

https://github.com/brandokoch/attention-is-all-you-need-paper/tree/master.

### Datasets 

Training on CIFAR10 dataset for classification. 
